{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dwarkanath\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import LSTM\n",
    "import string\n",
    "import h5py\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'a', 11: 'b', 12: 'c', 13: 'd', 14: 'e', 15: 'f', 16: 'g', 17: 'h', 18: 'i', 19: 'j', 20: 'k', 21: 'l', 22: 'm', 23: 'n', 24: 'o', 25: 'p', 26: 'q', 27: 'r', 28: 's', 29: 't', 30: 'u', 31: 'v', 32: 'w', 33: 'x', 34: 'y', 35: 'z', 36: 'A', 37: 'B', 38: 'C', 39: 'D', 40: 'E', 41: 'F', 42: 'G', 43: 'H', 44: 'I', 45: 'J', 46: 'K', 47: 'L', 48: 'M', 49: 'N', 50: 'O', 51: 'P', 52: 'Q', 53: 'R', 54: 'S', 55: 'T', 56: 'U', 57: 'V', 58: 'W', 59: 'X', 60: 'Y', 61: 'Z', 62: '!', 63: '\"', 64: '#', 65: '$', 66: '%', 67: '&', 68: \"'\", 69: '(', 70: ')', 71: '*', 72: '+', 73: ',', 74: '-', 75: '.', 76: '/', 77: ':', 78: ';', 79: '<', 80: '=', 81: '>', 82: '?', 83: '@', 84: '[', 85: '\\\\', 86: ']', 87: '^', 88: '_', 89: '`', 90: '{', 91: '|', 92: '}', 93: '~', 94: ' ', 95: '\\t', 96: '\\n', 97: '\\r', 98: '\\x0b', 99: '\\x0c'}\n"
     ]
    }
   ],
   "source": [
    "chars = string.printable\n",
    "vocab_size = len(chars)\n",
    "char_to_ix = {ch:i for i,ch in enumerate(chars)}\n",
    "ix_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "print(ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(filename):\n",
    "    with open(filename, 'r',encoding = 'utf8') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = get_text('tweets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ted Mosby https://t.co/E91LykbNIe\n",
      "What even was that performance. We're a long ball team now?\n",
      "@okmanideep @abhi_manjunath Someone give them lasagna, dammit.\n",
      "WTF is going on with Manchester City?\n",
      "RT @hotjamz: he's makin a list\n",
      "it's kept in plain text\n",
      "an elf just got phished\n",
      "you know what is next\n",
      "santa claus has leaked 2.2 billion useâ€¦\n",
      "RT @cantdrawarsenal: Happy Birthday Ramsey! https://t.co/l8xg4WsaD4\n",
      "Everytime I call a restaurant, they say, \"Yes, ma'am\" Er...\n",
      "@OdehEveryday This was in CStat?\n",
      "@discopiggu Doesn't matter as long as the reader knows what it means.\n",
      "People who grew up in the 90s now have purchasing power. So stuff that was popular then can be used to sell stuff now. That explains all the remakes of 90s songs and Google hiring Macaulay Culkin for their ad targeted at this age group.\n",
      "\n",
      "What other one hit wonders will return. ðŸ¤”\n",
      "PayTM recently did it with Kerala floods. Matching donations cost them a total of Rs. 1 crore . They collected over 30 crore from 12 lac users. If say 1%\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_idx(text):\n",
    "    X = []\n",
    "    for i in text:\n",
    "        try:\n",
    "            X.append(char_to_ix[i])\n",
    "        except KeyError:\n",
    "            X.append(99)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_data_idx(text[:20])\n",
    "Y = char_to_ix[text[20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tx = len(X)\n",
    "Tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[Y] =1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_vec(X, vocab_size):\n",
    "    Tx = len(X)\n",
    "    x = np.zeros(shape = [Tx, vocab_size])\n",
    "    for i, idx in enumerate(X):\n",
    "        if idx is not None:\n",
    "            x[i][idx] = 1\n",
    "        else:\n",
    "            continue\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = convert_to_vec(X, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(text, Tx, vocab_size, stride):\n",
    "    m = len(text)\n",
    "    x = np.zeros([m//stride, Tx, vocab_size])\n",
    "    y = np.zeros([m//stride, vocab_size])\n",
    "    for i in range(0, len(text)-Tx, stride):\n",
    "        j = i//3\n",
    "        X = get_data_idx(text[i:i+Tx])\n",
    "        x[j] = convert_to_vec(X, vocab_size)\n",
    "        try:\n",
    "            y[j, char_to_ix[text[i+Tx]]] = 1\n",
    "        except KeyError:\n",
    "            y[j,99] = 1\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = prepare_data(text[:300000], Tx, vocab_size, stride = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 20, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_model(input_shape, vocab_size):\n",
    "    Tx, vocab_size = input_shape\n",
    "    char_vecs = Input(shape = input_shape)\n",
    "    X = LSTM(units = 224, name = 'LSTM1')(char_vecs)\n",
    "    X = Dense(units = vocab_size, activation ='softmax', name = 'Dense1')(X)\n",
    "    model = Model(inputs = char_vecs, outputs = X, name = 'tweet_model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tweet_model([Tx, vocab_size], vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 20, 100)           0         \n",
      "_________________________________________________________________\n",
      "LSTM1 (LSTM)                 (None, 224)               291200    \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 100)               22500     \n",
      "=================================================================\n",
      "Total params: 313,700\n",
      "Trainable params: 313,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33333/33333 [==============================] - 76s 2ms/step - loss: 0.0351 - acc: 0.9905\n",
      "Epoch 2/10\n",
      "33333/33333 [==============================] - 77s 2ms/step - loss: 0.0330 - acc: 0.9908\n",
      "Epoch 3/10\n",
      "33333/33333 [==============================] - 71s 2ms/step - loss: 0.0313 - acc: 0.9911\n",
      "Epoch 4/10\n",
      "33333/33333 [==============================] - 70s 2ms/step - loss: 0.0297 - acc: 0.9914: 1s -\n",
      "Epoch 5/10\n",
      "33333/33333 [==============================] - 71s 2ms/step - loss: 0.0280 - acc: 0.9918: 3s - loss: - ETA:\n",
      "Epoch 6/10\n",
      "33333/33333 [==============================] - 69s 2ms/step - loss: 0.0263 - acc: 0.9922\n",
      "Epoch 7/10\n",
      "33333/33333 [==============================] - 77s 2ms/step - loss: 0.0244 - acc: 0.9927\n",
      "Epoch 8/10\n",
      "33333/33333 [==============================] - 74s 2ms/step - loss: 0.0226 - acc: 0.9932\n",
      "Epoch 9/10\n",
      "33333/33333 [==============================] - 79s 2ms/step - loss: 0.0206 - acc: 0.9937\n",
      "Epoch 10/10\n",
      "33333/33333 [==============================] - 79s 2ms/step - loss: 0.0187 - acc: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x266197bc940>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x , y, batch_size=16, verbose = 1, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.expand_dims(x[0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20, 100)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.argmax(x[0:1],axis = -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ted Mosby https://t.-\n",
      "c\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "X = np.argmax(x[0:1],axis = -1)\n",
    "Y_pred = np.argmax(y_pred, axis = -1)\n",
    "bs, Tx = X.shape\n",
    "for i in range(bs):\n",
    "    for j in range(Tx):\n",
    "        print(ix_to_char[X[i][j]], end = '')\n",
    "    print('-')\n",
    "    print(ix_to_char[Y_pred[i]])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    vocab_size = preds.shape[-1]\n",
    "    out = np.random.choice(range(vocab_size), p = preds.ravel())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sample(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_char[out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output():\n",
    "    generated = ''\n",
    "    usr_input = input(\"Write the beginning of your tweet. Your input is: \")\n",
    "    # zero pad the sentence to Tx characters.\n",
    "    sentence = ('{0:0>' + str(Tx) + '}').format(usr_input).lower()\n",
    "    generated += usr_input\n",
    "    print(usr_input, end = '')\n",
    "    for i in range(280):\n",
    "\n",
    "        x_pred = np.zeros((1, Tx, vocab_size))\n",
    "\n",
    "        for t, char in enumerate(sentence):\n",
    "            if char != '0':\n",
    "                x_pred[0, t, char_to_ix[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)\n",
    "        next_index = sample(preds)\n",
    "        next_char = ix_to_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        print(next_char, end = '')\n",
    "        if next_char == '\\n':\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the beginning of your tweet. Your input is: queen\n",
      "queen: AAst jate : @ambalyambay ak SHa*AS!\n"
     ]
    }
   ],
   "source": [
    "generate_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('tweet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('tweet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100000/100000 [==============================] - 208s 2ms/step - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 2/5\n",
      "100000/100000 [==============================] - 207s 2ms/step - loss: 0.0154 - acc: 0.9953\n",
      "Epoch 3/5\n",
      "100000/100000 [==============================] - 208s 2ms/step - loss: 0.0149 - acc: 0.9954\n",
      "Epoch 4/5\n",
      "100000/100000 [==============================] - ETA: 0s - loss: 0.0144 - acc: 0.995 - 183s 2ms/step - loss: 0.0144 - acc: 0.9955\n",
      "Epoch 5/5\n",
      "100000/100000 [==============================] - 193s 2ms/step - loss: 0.0140 - acc: 0.9956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f8f06d828>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x , y, batch_size=16, verbose = 1, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the beginning of your tweet. Your input is: Modi\n",
      "Modi curned andmervies winde\"! Wharara Charzea -_- https://t.co/InMXyzvvQr\n"
     ]
    }
   ],
   "source": [
    "generate_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('tweet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
